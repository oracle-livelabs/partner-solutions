{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6786f2-0bbc-48fa-be64-6f3c857d1d06",
   "metadata": {},
   "source": [
    "# Deploy the Fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7105c53-a2a3-49b5-a62b-4cd39b861688",
   "metadata": {},
   "source": [
    "## Set the OCI Authentication Method\n",
    "\n",
    "To deploy the model and model deployment to the Oracle Cloud Infrastructure (OCI), users must authenticate using a supported method, for example, API keys or resource principal. By now, you would have configured a dynamic group that includes the OCI Data Science notebook sessions, and a policy that will allow a notebook session to create a model in the model catalog, and deploy the model. Hence, we will use the resource principal method to authenticate to the OCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8fde5-cd28-4bd4-b226-2c16cc7190aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "\n",
    "ads.set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5f587-f8c3-4776-bb98-3b845bdda79f",
   "metadata": {},
   "source": [
    "## Set Variables\n",
    "\n",
    "The `model_path` is the file system path to where the model was saved to in the previous lab. \n",
    "\n",
    "> **IMPORTANT**\n",
    "> Set the values of the `inference_conda_env_pack_path` and `training_conda_env_pack_path` variables using the pack path of the Conda environment that was deployed to the Object Storage bucket in an earlier lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbe7e2-2d04-4d01-9365-073cbb456b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "pretrained_model_name = \"google-bert/bert-base-uncased\"\n",
    "model_path = \"./review_model\"\n",
    "model_display_name = \"review_model\"\n",
    "artifact_path = \"./review_model_artifact\"\n",
    "python_version = \"3.9\"\n",
    "inference_conda_env_pack_path = \"oci://<BUCKET_NAME>@<TENANCY_NAMESPACE>/conda_environments/<ARCHITECTURE>/<CONDA_ENV_NAME>/<VERSION>/<CONDA_ENV_SLUG>\"\n",
    "training_conda_env_pack_path = \"oci://<BUCKET_NAME>@<TENANCY_NAMESPACE>/conda_environments/<ARCHITECTURE>/<CONDA_ENV_NAME>/<VERSION>/<CONDA_ENV_SLUG>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886409e-157c-4240-a598-ec626f3d6f9b",
   "metadata": {},
   "source": [
    "## Prepare the Model Artifact\n",
    "\n",
    "The Oracle Accelerated Data Science (ADS) is a Python package managed by the OCI Data Science service team. It provides utilities for assisting data scientists to work with OCI components and performing common data science tasks. We will use ADS to prepare the model artifacts, registering the model, and then deploying it to the OCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f11500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model.framework.huggingface_model import HuggingFacePipelineModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Instantiate the same tokenizer used for the model training.\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "# Load the model saved from the previous lab.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create the pipeline.\n",
    "inference = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Instantiate the ADS HuggingFace pipeline.\n",
    "huggingface_pipeline_model = HuggingFacePipelineModel(estimator=inference, artifact_dir=artifact_path)\n",
    "\n",
    "# Prepare the pipeline for saving to the catalog and eventual deployment.\n",
    "huggingface_pipeline_model.prepare(\n",
    "    inference_conda_env=inference_conda_env_pack_path,\n",
    "    inference_python_version=python_version,\n",
    "    training_conda_env=training_conda_env_pack_path,\n",
    "    use_case_type=UseCaseType.SENTIMENT_ANALYSIS,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367595e-fe18-4999-9d8b-e943fd82095d",
   "metadata": {},
   "source": [
    "## Generate a Summary Table of the Model's Status\n",
    "\n",
    "The summary table shows which methods are available to call and which ones arenâ€™t. Plus it outlines what each method does. If extra actions are required, it also shows those actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ca61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_pipeline_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a6afb-ea46-423d-a1f2-076e15e66045",
   "metadata": {},
   "source": [
    "## Register the Model to the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181c0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = huggingface_pipeline_model.save(\n",
    "    display_name=model_display_name,\n",
    "    description=\"Fine-tuned BERT model to automatically label a review.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ce09a-3154-411c-abcf-7887adccb427",
   "metadata": {},
   "source": [
    "## Validate the Saved Model\n",
    "\n",
    "Execute the `.introspect()` method to make final checks on the artifacts. All results should show `Passed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0493111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_pipeline_model.introspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6181c-a58f-42f9-8cba-d9d274963199",
   "metadata": {},
   "source": [
    "## Deploy the Model and Display the Deployment Endpoint URL\n",
    "\n",
    "Deploy the registered model. Specify the required compute shape to perform the inference tasks. Optionally, and preferably, create an OCI log group containing two logs for capturing the outputs generated when the model is accessed, and the inference task is performed.\n",
    "\n",
    "We will print the endpoint URL for invoking the deployed model, however, you may also obtain this through the OCI Console.\n",
    "\n",
    "```\n",
    "https://modeldeployment.{region}.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.xxx.xxxxx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_pipeline_model.deploy(\n",
    "    display_name=\"LiveLabs_Review_Model\",\n",
    "#     deployment_log_group_id=\"ocid1.loggroup.oc1.xxx.xxxxx\",\n",
    "#     deployment_access_log_id=\"ocid1.log.oc1.xxx.xxxxx\",\n",
    "#     deployment_predict_log_id=\"ocid1.log.oc1.xxx.xxxxx\",\n",
    "\n",
    "    # Shape config details mandatory for flexible shapes:\n",
    "    deployment_instance_shape=\"VM.Standard.E4.Flex\",\n",
    "    deployment_ocpus=1,\n",
    "    deployment_memory_in_gbs=16,\n",
    ")\n",
    "\n",
    "print(f\"Endpoint: {huggingface_pipeline_model.model_deployment.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449ec49-bfdc-4072-a421-d16bd2612572",
   "metadata": {},
   "source": [
    "## Test the Deployed Model\n",
    "\n",
    "In this final cell, call the predict endpoint for the model that you have just deployed on the OCI. The only input is the review text, and if successful, a JSON response will be returned containing the assigned label (review rating), and a prediction score.\n",
    "\n",
    "Example response:\n",
    "\n",
    "```json\n",
    "{'prediction': [{'label': 'LABEL_2', 'score': 0.2783530652523041}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921ed49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import oci\n",
    "\n",
    "review = \"\"\"\n",
    "I have been through other brands of individual pods coffee brewing, like Keurig or Kienna, not Tassimo. This \n",
    "time I would like to try Nespresso which uses up to 19-bar high pressure to extract concentrated coffee of \n",
    "two sizes, espresso and lungo. The delivery was Prime and quick, the product is brand new and made by well \n",
    "known quality Breville brand. I have only used it for about 10 times in 4 days and so far, the temperature \n",
    "is hotter (preferred) than my Keurig or even the regular Hamilton Beach brew station. The only downside I may \n",
    "add would be when I will have to descale the machine using only the proprietary Nespresso descaling liquid \n",
    "sold separately. I usually only used white vinegar to clean my coffee drip machines or Keurig. This is part \n",
    "of the only Nespresso model ( Original Line, not Virtuo) that may be able to use cheaper compatible pods that \n",
    "may go as low as almost half the price of original Nespresso pods.\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\n",
    "    url=huggingface_pipeline_model.model_deployment.url + \"/predict\",\n",
    "    auth = oci.auth.signers.get_resource_principals_signer(),\n",
    "    json = f\"[\\\"{review}\\\"]\"\n",
    ") \n",
    "\n",
    "assert response.status_code == 200, \"Request failed.\"\n",
    "\n",
    "print(json.loads(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:review_v1]",
   "language": "python",
   "name": "conda-env-review_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
