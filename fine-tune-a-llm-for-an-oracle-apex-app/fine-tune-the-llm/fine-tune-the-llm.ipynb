{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51be56a6-d1e3-464e-b941-adf1b73c5839",
   "metadata": {},
   "source": [
    "# Fine-tune the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafb053-aaa9-4d4c-83b8-1615ac04cc6f",
   "metadata": {},
   "source": [
    "## Install or Upgrade Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f87ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet \\\n",
    "    pip \\\n",
    "    transformers[torch]==4.41.2 \\\n",
    "    datasets==2.20.0 \\\n",
    "    evaluate==0.4.2 \\\n",
    "    accelerate==0.31.0 \\\n",
    "    bottleneck==1.3.6 \\\n",
    "    mlflow==2.13.2 \\\n",
    "    oracle-ads==2.11.12 \\\n",
    "    oci-cli==3.43.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099d023-fb9d-42ec-b69e-6a94b586313c",
   "metadata": {},
   "source": [
    "## Load Dataset for Model Training\n",
    "\n",
    "Load the [Yelp review dataset](https://huggingface.co/datasets/Yelp/yelp_review_full) containing user-submitted reviews on Yelp's website. Each row contains the review content and a label corresponding to the number of stars (from 1 to 5) awarded by the reviewer. The dataset is split into 650K rows for training, and 50K rows for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdf766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7ab68-7847-4c94-9ac7-7c169fbdf1c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Variables\n",
    "\n",
    "Reduce the amounts of `number_of_train_records` and `number_of_test_records` for faster training but lower accuracy. Increasing these values will improve the model accuracy but the training will take a longer time to complete. You may also modify the number of epochs or training cycles. Training speed will greatly improved if performed on a compute with GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75df91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "pretrained_model_name = \"google-bert/bert-base-uncased\"\n",
    "number_of_train_records = 50\n",
    "number_of_test_records = 50\n",
    "number_of_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1d08b-65e4-414d-88e1-b77fba051de7",
   "metadata": {},
   "source": [
    "## Prepare the Training and Testing Datasets\n",
    "\n",
    "The `text` element in the dataset must first be tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801574b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(number_of_train_records))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(number_of_test_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73363e66-07d6-40b9-8ba2-fca91c545bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7957c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=5)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"review_trainer\", eval_strategy=\"epoch\", \n",
    "                                  num_train_epochs=number_of_epochs)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb74e1a-79a2-4412-9714-0e7a9ac3016a",
   "metadata": {},
   "source": [
    "## Perform the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9607b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702fc0b-fe9c-4aae-9f23-eb569813d5cb",
   "metadata": {},
   "source": [
    "## Use the Model to Predict a Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ba133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "inference = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "review = \"\"\"\n",
    "I have been through other brands of individual pods coffee brewing, like Keurig or Kienna, not Tassimo. \n",
    "This time I would like to try Nespresso which uses up to 19-bar high pressure to extract concentrated \n",
    "coffee of two sizes, espresso and lungo. The delivery was Prime and quick, the product is brand new \n",
    "and made by well known quality Breville brand. I have only used it for about 10 times in 4 days and so \n",
    "far, the temperature is hotter (preferred) than my Keurig or even the regular Hamilton Beach brew \n",
    "station. The only downside I may add would be when I will have to descale the machine using only the \n",
    "proprietary Nespresso descaling liquid sold separately. I usually only used white vinegar to clean \n",
    "my coffee drip machines or Keurig. This is part of the only Nespresso model ( Original Line, not \n",
    "Virtuo) that may be able to use cheaper compatible pods that may go as low as almost half the price of \n",
    "original Nespresso pods.\n",
    "\"\"\"\n",
    "\n",
    "inference(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc60e-2374-41ee-ba3c-0a7973bc96cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the Model to the Storage for the Next Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc48219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('./review_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:review_v1]",
   "language": "python",
   "name": "conda-env-review_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
